########################
## CONFIGURATION FILE ##
########################

[TEI_PARSING]
##########################################################################
## If TEI parsing was not done by an external process (eg. PhiloLogic), ##
## you can parse your source and target files using the provided xml    ##
## parser in utils/                                                     ##
##########################################################################

# Defines whether to parse source files
parse_source_files = yes

# Defines path to file containing words to keep (useful for dirty OCR)
# Default is keeping all words
source_words_to_keep = all

# Defines whether to parse target files
parse_target_files = yes

# Defines path to file containing words to keep (useful for dirty OCR)
# Default is keeping all words
target_words_to_keep = all


[PREPROCESSING]
# Defines what object level to divide each text into
# Only posssible with a Philologic4 index
# Useful to break up a single document into smaller text units
source_text_object_level = doc
target_text_object_level = doc

# Defines how many tokens constitute a ngram
ngram = 3

# Defines size of gap autorized in ngram. If not 0, this will generate multiple ngrams within a window size of ngram+gap
# Note that you may need to adjust your minimum number of ngrams for matches to avoid short matches as a result.
gap = 0

# The word order must be respected
word_order = yes

# Language: set the language for various normalization tasks
# such as stemming, lemmatizing, word mapping...etc
language =

# Modernize language if modernization is available for your language: currently only French is supported.
modernize = yes

# Stem words using the Porter Stemmer
stemmer = yes

# Lemmatizer: path to lemmatizer file where each line contains the inflected form and
# the corresponding lemma separated by a tab
lemmatizer =

# Lowercase words
lowercase = yes

# Remove numbers
numbers = yes

# Minimum word length
minimum_word_length = 2

# Stopwords: path to stopword list
stopwords =


[MATCHING]
########################
## PROCESSING OPTIONS ##
########################

# Sort files prior to matching. This may be important when wanting to avoid
# comparing a source file with a target file that occurs later in time
sort_by = year

# Turn on batch mode for source files and/or target_files and define the size of each batch as
# a dividing number
source_batch = 1
target_batch = 1

# Size of left and right context in bytes
context_size = 300

#########################
## MATCHING PARAMETERS ##
#########################

# Size of ngram window to be initially evaluated in the sequence aligner
matching_window_size = 30

# Minimum number of shared ngrams between docs to start a comparison
minimum_matching_ngrams_in_docs = 4

# Percentage of shared ngrams between 2 docs to consider the target as a duplicate of source
duplicate_threshold = 50

# Minimum number of matching ngrams in ngram window
minimum_matching_ngrams_in_window = 4

# Maximum gap authorized between matching ngrams
max_gap = 15

# Minimum number of matching ngrams to constitute a match
minimum_matching_ngrams  = 4

# Automatically increase max_gap once minimum_matching_ngrams is reached
flex_gap = false

###################################
## PASSAGE MERGING AND EXTENDING ##
###################################

# Merge passages within n number of byte: number defined by passage length and the passage_distance_multiplier option.
merge_passages_on_byte_distance = true

# Combine passage which are within (multiplier * length of previous passage) bytes. Needs merge_passages_on_byte_distance set to true
passage_distance_multiplier = 0.5

# Merge passages within n number of ngrams: the value used is the matching_window_size defaulting to 20
merge_passages_on_ngram_distance = true

#################################
## BANALITY DETECTION SETTINGS ##
#################################

# Define the top n most common ngrams from source and target common ngrams
most_common_ngram_threshold = 1000

# The top common_ngrams_in_docs between two docs: used to define common, or banal ngrams.
banal_ngrams = 25

# Defines the maximum amount of common ngrams between two docs: this is effectively a banality measure.
# Ex: If we want to dismiss matches where more than 75% of matching ngrams are among the top n common ngrams between both docs
# we set the common_ngrams_limit to 75
common_ngrams_limit = 75


[WEB_APPLICATION]
##################################
#### WEB APP LOADING OPTIONS ####
##################################

# Local directory where web application should be installed
web_application_directory = /var/www/html/text-align/

# URL of API server
api_server = http://localhost/text-align-api/

# Name of PostgreSQL table where results are stored
table_name =

# In the following section, set the type for fields when stored in PostgreSQL
# Supported types are TEXT and INTEGER. If the field is not set, it will default to text.
source_year = INTEGER
target_year = INTEGER

# Link aligments to PhiloLogic databases
source_database = false
source_database_link =
target_database = false
target_database_link =
